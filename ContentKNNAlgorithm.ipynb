{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ContentKNNAlgorithm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6MM6bSmPlL8"
      },
      "source": [
        "# Import the machine learning libraries.\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "import re\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import itertools\n",
        "import math\n",
        "import heapq"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqiI_C3wPqCx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef82a12b-7a25-4f1f-e283-4ee91933d3a9"
      },
      "source": [
        "# Install Surprise which is a Python scikit for building and analyzing recommender systems that deal with explicit rating data.\n",
        "!pip install scikit-surprise"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (0.17.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (1.15.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9Akh-Sfcjme"
      },
      "source": [
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "from surprise import SVD\n",
        "from surprise import KNNBaseline\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise.model_selection import LeaveOneOut\n",
        "from surprise import accuracy\n",
        "from surprise import AlgoBase\n",
        "from surprise import PredictionImpossible"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THVii55EdVP_"
      },
      "source": [
        "class MovieLens:\n",
        "\n",
        "    movieID_to_name = {}\n",
        "    name_to_movieID = {}\n",
        "    ratingsPath = '../ml-latest-small/ratings.csv'\n",
        "    moviesPath = '../ml-latest-small/movies.csv'\n",
        "    \n",
        "    def loadMovieLensLatestSmall(self):\n",
        "\n",
        "        # Look for files relative to the directory we are running from\n",
        "        os.chdir(os.path.dirname(sys.argv[0]))\n",
        "\n",
        "        ratingsDataset = 0\n",
        "        self.movieID_to_name = {}\n",
        "        self.name_to_movieID = {}\n",
        "\n",
        "        reader = Reader(line_format='user item rating timestamp', sep=',', skip_lines=1)\n",
        "\n",
        "        ratingsDataset = Dataset.load_from_file(self.ratingsPath, reader=reader)\n",
        "\n",
        "        with open(self.moviesPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
        "                movieReader = csv.reader(csvfile)\n",
        "                next(movieReader)  #Skip header line\n",
        "                for row in movieReader:\n",
        "                    movieID = int(row[0])\n",
        "                    movieName = row[1]\n",
        "                    self.movieID_to_name[movieID] = movieName\n",
        "                    self.name_to_movieID[movieName] = movieID\n",
        "\n",
        "        return ratingsDataset\n",
        "\n",
        "    def getUserRatings(self, user):\n",
        "        userRatings = []\n",
        "        hitUser = False\n",
        "        with open(self.ratingsPath, newline='') as csvfile:\n",
        "            ratingReader = csv.reader(csvfile)\n",
        "            next(ratingReader)\n",
        "            for row in ratingReader:\n",
        "                userID = int(row[0])\n",
        "                if (user == userID):\n",
        "                    movieID = int(row[1])\n",
        "                    rating = float(row[2])\n",
        "                    userRatings.append((movieID, rating))\n",
        "                    hitUser = True\n",
        "                if (hitUser and (user != userID)):\n",
        "                    break\n",
        "\n",
        "        return userRatings\n",
        "\n",
        "    def getPopularityRanks(self):\n",
        "        ratings = defaultdict(int)\n",
        "        rankings = defaultdict(int)\n",
        "        with open(self.ratingsPath, newline='') as csvfile:\n",
        "            ratingReader = csv.reader(csvfile)\n",
        "            next(ratingReader)\n",
        "            for row in ratingReader:\n",
        "                movieID = int(row[1])\n",
        "                ratings[movieID] += 1\n",
        "        rank = 1\n",
        "        for movieID, ratingCount in sorted(ratings.items(), key=lambda x: x[1], reverse=True):\n",
        "            rankings[movieID] = rank\n",
        "            rank += 1\n",
        "        return rankings\n",
        "    \n",
        "    def getGenres(self):\n",
        "        genres = defaultdict(list)\n",
        "        genreIDs = {}\n",
        "        maxGenreID = 0\n",
        "        with open(self.moviesPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
        "            movieReader = csv.reader(csvfile)\n",
        "            next(movieReader)  #Skip header line\n",
        "            for row in movieReader:\n",
        "                movieID = int(row[0])\n",
        "                genreList = row[2].split('|')\n",
        "                genreIDList = []\n",
        "                for genre in genreList:\n",
        "                    if genre in genreIDs:\n",
        "                        genreID = genreIDs[genre]\n",
        "                    else:\n",
        "                        genreID = maxGenreID\n",
        "                        genreIDs[genre] = genreID\n",
        "                        maxGenreID += 1\n",
        "                    genreIDList.append(genreID)\n",
        "                genres[movieID] = genreIDList\n",
        "        # Convert integer-encoded genre lists to bitfields that we can treat as vectors\n",
        "        for (movieID, genreIDList) in genres.items():\n",
        "            bitfield = [0] * maxGenreID\n",
        "            for genreID in genreIDList:\n",
        "                bitfield[genreID] = 1\n",
        "            genres[movieID] = bitfield            \n",
        "        \n",
        "        return genres\n",
        "    \n",
        "    def getYears(self):\n",
        "        p = re.compile(r\"(?:\\((\\d{4})\\))?\\s*$\")\n",
        "        years = defaultdict(int)\n",
        "        with open(self.moviesPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
        "            movieReader = csv.reader(csvfile)\n",
        "            next(movieReader)\n",
        "            for row in movieReader:\n",
        "                movieID = int(row[0])\n",
        "                title = row[1]\n",
        "                m = p.search(title)\n",
        "                year = m.group(1)\n",
        "                if year:\n",
        "                    years[movieID] = int(year)\n",
        "        return years\n",
        "    \n",
        "    def getMiseEnScene(self):\n",
        "        mes = defaultdict(list)\n",
        "        with open(\"../ml-latest-small/LLVisualFeatures13K_Log.csv\", newline='') as csvfile:\n",
        "            mesReader = csv.reader(csvfile)\n",
        "            next(mesReader)\n",
        "            for row in mesReader:\n",
        "                movieID = int(row[0])\n",
        "                avgShotLength = float(row[1])\n",
        "                meanColorVariance = float(row[2])\n",
        "                stddevColorVariance = float(row[3])\n",
        "                meanMotion = float(row[4])\n",
        "                stddevMotion = float(row[5])\n",
        "                meanLightingKey = float(row[6])\n",
        "                numShots = float(row[7])\n",
        "                mes[movieID] = [avgShotLength, meanColorVariance, stddevColorVariance,\n",
        "                   meanMotion, stddevMotion, meanLightingKey, numShots]\n",
        "        return mes\n",
        "    \n",
        "    def getMovieName(self, movieID):\n",
        "        if movieID in self.movieID_to_name:\n",
        "            return self.movieID_to_name[movieID]\n",
        "        else:\n",
        "            return \"\"\n",
        "        \n",
        "    def getMovieID(self, movieName):\n",
        "        if movieName in self.name_to_movieID:\n",
        "            return self.name_to_movieID[movieName]\n",
        "        else:\n",
        "            return 0"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1m421ojeeHu"
      },
      "source": [
        "class RecommenderMetrics:\n",
        "\n",
        "    def MAE(self, predictions):\n",
        "        return accuracy.mae(predictions, verbose=False)\n",
        "\n",
        "    def RMSE(self, predictions):\n",
        "        return accuracy.rmse(predictions, verbose=False)\n",
        "\n",
        "    def GetTopN(self, predictions, n=10, minimumRating=4.0):\n",
        "        topN = defaultdict(list)\n",
        "\n",
        "        for userID, movieID, actualRating, estimatedRating, _ in predictions:\n",
        "            if (estimatedRating >= minimumRating):\n",
        "                topN[int(userID)].append((int(movieID), estimatedRating))\n",
        "\n",
        "        for userID, ratings in topN.items():\n",
        "            ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "            topN[int(userID)] = ratings[:n]\n",
        "\n",
        "        return topN\n",
        "\n",
        "    def HitRate(self, topNPredicted, leftOutPredictions):\n",
        "        hits = 0\n",
        "        total = 0\n",
        "\n",
        "        # For each left-out rating\n",
        "        for leftOut in leftOutPredictions:\n",
        "            userID = leftOut[0]\n",
        "            leftOutMovieID = leftOut[1]\n",
        "            # Is it in the predicted top 10 for this user?\n",
        "            hit = False\n",
        "            for movieID, predictedRating in topNPredicted[int(userID)]:\n",
        "                if (int(leftOutMovieID) == int(movieID)):\n",
        "                    hit = True\n",
        "                    break\n",
        "            if (hit) :\n",
        "                hits += 1\n",
        "\n",
        "            total += 1\n",
        "\n",
        "        # Compute overall precision\n",
        "        return hits/total\n",
        "\n",
        "    def CumulativeHitRate(self, topNPredicted, leftOutPredictions, ratingCutoff=0):\n",
        "        hits = 0\n",
        "        total = 0\n",
        "\n",
        "        # For each left-out rating\n",
        "        for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
        "            # Only look at ability to recommend things the users actually liked...\n",
        "            if (actualRating >= ratingCutoff):\n",
        "                # Is it in the predicted top 10 for this user?\n",
        "                hit = False\n",
        "                for movieID, predictedRating in topNPredicted[int(userID)]:\n",
        "                    if (int(leftOutMovieID) == movieID):\n",
        "                        hit = True\n",
        "                        break\n",
        "                if (hit) :\n",
        "                    hits += 1\n",
        "\n",
        "                total += 1\n",
        "\n",
        "        # Compute overall precision\n",
        "        return hits/total\n",
        "\n",
        "    def RatingHitRate(self, topNPredicted, leftOutPredictions):\n",
        "        hits = defaultdict(float)\n",
        "        total = defaultdict(float)\n",
        "\n",
        "        # For each left-out rating\n",
        "        for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
        "            # Is it in the predicted top N for this user?\n",
        "            hit = False\n",
        "            for movieID, predictedRating in topNPredicted[int(userID)]:\n",
        "                if (int(leftOutMovieID) == movieID):\n",
        "                    hit = True\n",
        "                    break\n",
        "            if (hit) :\n",
        "                hits[actualRating] += 1\n",
        "\n",
        "            total[actualRating] += 1\n",
        "\n",
        "        # Compute overall precision\n",
        "        for rating in sorted(hits.keys()):\n",
        "            print (rating, hits[rating] / total[rating])\n",
        "\n",
        "    def AverageReciprocalHitRank(self, topNPredicted, leftOutPredictions):\n",
        "        summation = 0\n",
        "        total = 0\n",
        "        # For each left-out rating\n",
        "        for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
        "            # Is it in the predicted top N for this user?\n",
        "            hitRank = 0\n",
        "            rank = 0\n",
        "            for movieID, predictedRating in topNPredicted[int(userID)]:\n",
        "                rank = rank + 1\n",
        "                if (int(leftOutMovieID) == movieID):\n",
        "                    hitRank = rank\n",
        "                    break\n",
        "            if (hitRank > 0) :\n",
        "                summation += 1.0 / hitRank\n",
        "\n",
        "            total += 1\n",
        "\n",
        "        return summation / total\n",
        "\n",
        "    # What percentage of users have at least one \"good\" recommendation\n",
        "    def UserCoverage(self, topNPredicted, numUsers, ratingThreshold=0):\n",
        "        hits = 0\n",
        "        for userID in topNPredicted.keys():\n",
        "            hit = False\n",
        "            for movieID, predictedRating in topNPredicted[userID]:\n",
        "                if (predictedRating >= ratingThreshold):\n",
        "                    hit = True\n",
        "                    break\n",
        "            if (hit):\n",
        "                hits += 1\n",
        "\n",
        "        return hits / numUsers\n",
        "\n",
        "    def Diversity(self, topNPredicted, simsAlgo):\n",
        "        n = 0\n",
        "        total = 0\n",
        "        simsMatrix = simsAlgo.compute_similarities()\n",
        "        for userID in topNPredicted.keys():\n",
        "            pairs = itertools.combinations(topNPredicted[userID], 2)\n",
        "            for pair in pairs:\n",
        "                movie1 = pair[0][0]\n",
        "                movie2 = pair[1][0]\n",
        "                innerID1 = simsAlgo.trainset.to_inner_iid(str(movie1))\n",
        "                innerID2 = simsAlgo.trainset.to_inner_iid(str(movie2))\n",
        "                similarity = simsMatrix[innerID1][innerID2]\n",
        "                total += similarity\n",
        "                n += 1\n",
        "\n",
        "        S = total / n\n",
        "        return (1-S)\n",
        "\n",
        "    def Novelty(self, topNPredicted, rankings):\n",
        "        n = 0\n",
        "        total = 0\n",
        "        for userID in topNPredicted.keys():\n",
        "            for rating in topNPredicted[userID]:\n",
        "                movieID = rating[0]\n",
        "                rank = rankings[movieID]\n",
        "                total += rank\n",
        "                n += 1\n",
        "        return total / n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePGIcUBh_txI"
      },
      "source": [
        "rm = RecommenderMetrics()\n",
        "\n",
        "class EvaluatedAlgorithm:\n",
        "    \n",
        "    def __init__(self, algorithm, name):\n",
        "        self.algorithm = algorithm\n",
        "        self.name = name\n",
        "        \n",
        "    def Evaluate(self, evaluationData, doTopN, n=10, verbose=True):\n",
        "        metrics = {}\n",
        "        # Compute accuracy\n",
        "        if (verbose):\n",
        "            print(\"Evaluating accuracy...\")\n",
        "        self.algorithm.fit(evaluationData.GetTrainSet())\n",
        "        predictions = self.algorithm.test(evaluationData.GetTestSet())\n",
        "        metrics[\"RMSE\"] = rm.RMSE(predictions)\n",
        "        metrics[\"MAE\"] = rm.MAE(predictions)\n",
        "        \n",
        "        if (doTopN):\n",
        "            # Evaluate top-10 with Leave One Out testing\n",
        "            if (verbose):\n",
        "                print(\"Evaluating top-N with leave-one-out...\")\n",
        "            self.algorithm.fit(evaluationData.GetLOOCVTrainSet())\n",
        "            leftOutPredictions = self.algorithm.test(evaluationData.GetLOOCVTestSet())        \n",
        "            # Build predictions for all ratings not in the training set\n",
        "            allPredictions = self.algorithm.test(evaluationData.GetLOOCVAntiTestSet())\n",
        "            # Compute top 10 recs for each user\n",
        "            topNPredicted = rm.GetTopN(allPredictions, n)\n",
        "            if (verbose):\n",
        "                print(\"Computing hit-rate and rank metrics...\")\n",
        "            # See how often we recommended a movie the user actually rated\n",
        "            metrics[\"HR\"] = rm.HitRate(topNPredicted, leftOutPredictions)   \n",
        "            # See how often we recommended a movie the user actually liked\n",
        "            metrics[\"cHR\"] = rm.CumulativeHitRate(topNPredicted, leftOutPredictions)\n",
        "            # Compute ARHR\n",
        "            metrics[\"ARHR\"] = rm.AverageReciprocalHitRank(topNPredicted, leftOutPredictions)\n",
        "        \n",
        "            #Evaluate properties of recommendations on full training set\n",
        "            if (verbose):\n",
        "                print(\"Computing recommendations with full data set...\")\n",
        "            self.algorithm.fit(evaluationData.GetFullTrainSet())\n",
        "            allPredictions = self.algorithm.test(evaluationData.GetFullAntiTestSet())\n",
        "            topNPredicted = rm.GetTopN(allPredictions, n)\n",
        "            if (verbose):\n",
        "                print(\"Analyzing coverage, diversity, and novelty...\")\n",
        "            # Print user coverage with a minimum predicted rating of 4.0:\n",
        "            metrics[\"Coverage\"] = rm.UserCoverage(  topNPredicted, \n",
        "                                                                   evaluationData.GetFullTrainSet().n_users, \n",
        "                                                                   ratingThreshold=4.0)\n",
        "            # Measure diversity of recommendations:\n",
        "            metrics[\"Diversity\"] = rm.Diversity(topNPredicted, evaluationData.GetSimilarities())\n",
        "            \n",
        "            # Measure novelty (average popularity rank of recommendations):\n",
        "            metrics[\"Novelty\"] = rm.Novelty(topNPredicted, \n",
        "                                                            evaluationData.GetPopularityRankings())\n",
        "        \n",
        "        if (verbose):\n",
        "            print(\"Analysis complete.\")\n",
        "    \n",
        "        return metrics\n",
        "    \n",
        "    def GetName(self):\n",
        "        return self.name\n",
        "    \n",
        "    def GetAlgorithm(self):\n",
        "        return self.algorithm"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT4GxJMj_5kB"
      },
      "source": [
        "class EvaluationData:\n",
        "    \n",
        "    def __init__(self, data, popularityRankings):\n",
        "        \n",
        "        self.rankings = popularityRankings\n",
        "        \n",
        "        #Build a full training set for evaluating overall properties\n",
        "        self.fullTrainSet = data.build_full_trainset()\n",
        "        self.fullAntiTestSet = self.fullTrainSet.build_anti_testset()\n",
        "        \n",
        "        #Build a 75/25 train/test split for measuring accuracy\n",
        "        self.trainSet, self.testSet = train_test_split(data, test_size=.25, random_state=1)\n",
        "        \n",
        "        #Build a \"leave one out\" train/test split for evaluating top-N recommenders\n",
        "        #And build an anti-test-set for building predictions\n",
        "        LOOCV = LeaveOneOut(n_splits=1, random_state=1)\n",
        "        for train, test in LOOCV.split(data):\n",
        "            self.LOOCVTrain = train\n",
        "            self.LOOCVTest = test\n",
        "            \n",
        "        self.LOOCVAntiTestSet = self.LOOCVTrain.build_anti_testset()\n",
        "        \n",
        "        #Compute similarty matrix between items so we can measure diversity\n",
        "        sim_options = {'name': 'cosine', 'user_based': False}\n",
        "        self.simsAlgo = KNNBaseline(sim_options=sim_options)\n",
        "        self.simsAlgo.fit(self.fullTrainSet)\n",
        "            \n",
        "    def GetFullTrainSet(self):\n",
        "        return self.fullTrainSet\n",
        "    \n",
        "    def GetFullAntiTestSet(self):\n",
        "        return self.fullAntiTestSet\n",
        "    \n",
        "    def GetAntiTestSetForUser(self, testSubject):\n",
        "        trainset = self.fullTrainSet\n",
        "        fill = trainset.global_mean\n",
        "        anti_testset = []\n",
        "        u = trainset.to_inner_uid(str(testSubject))\n",
        "        user_items = set([j for (j, _) in trainset.ur[u]])\n",
        "        anti_testset += [(trainset.to_raw_uid(u), trainset.to_raw_iid(i), fill) for\n",
        "                                 i in trainset.all_items() if\n",
        "                                 i not in user_items]\n",
        "        return anti_testset\n",
        "\n",
        "    def GetTrainSet(self):\n",
        "        return self.trainSet\n",
        "    \n",
        "    def GetTestSet(self):\n",
        "        return self.testSet\n",
        "    \n",
        "    def GetLOOCVTrainSet(self):\n",
        "        return self.LOOCVTrain\n",
        "    \n",
        "    def GetLOOCVTestSet(self):\n",
        "        return self.LOOCVTest\n",
        "    \n",
        "    def GetLOOCVAntiTestSet(self):\n",
        "        return self.LOOCVAntiTestSet\n",
        "    \n",
        "    def GetSimilarities(self):\n",
        "        return self.simsAlgo\n",
        "    \n",
        "    def GetPopularityRankings(self):\n",
        "        return self.rankings"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4djOUYUI_-Ar"
      },
      "source": [
        "class Evaluator:\n",
        "    \n",
        "    algorithms = []\n",
        "    \n",
        "    def __init__(self, dataset, rankings):\n",
        "        ed = EvaluationData(dataset, rankings)\n",
        "        self.dataset = ed\n",
        "        \n",
        "    def AddAlgorithm(self, algorithm, name):\n",
        "        alg = EvaluatedAlgorithm(algorithm, name)\n",
        "        self.algorithms.append(alg)\n",
        "        \n",
        "    def Evaluate(self, doTopN):\n",
        "        results = {}\n",
        "        for algorithm in self.algorithms:\n",
        "            print(\"Evaluating \", algorithm.GetName(), \"...\")\n",
        "            results[algorithm.GetName()] = algorithm.Evaluate(self.dataset, doTopN)\n",
        "\n",
        "        # Print results\n",
        "        print(\"\\n\")\n",
        "        \n",
        "        if (doTopN):\n",
        "            print(\"{:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10}\".format(\n",
        "                    \"Algorithm\", \"RMSE\", \"MAE\", \"HR\", \"cHR\", \"ARHR\", \"Coverage\", \"Diversity\", \"Novelty\"))\n",
        "            for (name, metrics) in results.items():\n",
        "                print(\"{:<10} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f}\".format(\n",
        "                        name, metrics[\"RMSE\"], metrics[\"MAE\"], metrics[\"HR\"], metrics[\"cHR\"], metrics[\"ARHR\"],\n",
        "                                      metrics[\"Coverage\"], metrics[\"Diversity\"], metrics[\"Novelty\"]))\n",
        "        else:\n",
        "            print(\"{:<10} {:<10} {:<10}\".format(\"Algorithm\", \"RMSE\", \"MAE\"))\n",
        "            for (name, metrics) in results.items():\n",
        "                print(\"{:<10} {:<10.4f} {:<10.4f}\".format(name, metrics[\"RMSE\"], metrics[\"MAE\"]))\n",
        "                \n",
        "        print(\"\\nLegend:\\n\")\n",
        "        print(\"RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\")\n",
        "        print(\"MAE:       Mean Absolute Error. Lower values mean better accuracy.\")\n",
        "        if (doTopN):\n",
        "            print(\"HR:        Hit Rate; how often we are able to recommend a left-out rating. Higher is better.\")\n",
        "            print(\"cHR:       Cumulative Hit Rate; hit rate, confined to ratings above a certain threshold. Higher is better.\")\n",
        "            print(\"ARHR:      Average Reciprocal Hit Rank - Hit rate that takes the ranking into account. Higher is better.\" )\n",
        "            print(\"Coverage:  Ratio of users for whom recommendations above a certain threshold exist. Higher is better.\")\n",
        "            print(\"Diversity: 1-S, where S is the average similarity score between every possible pair of recommendations\")\n",
        "            print(\"           for a given user. Higher means more diverse.\")\n",
        "            print(\"Novelty:   Average popularity rank of recommended items. Higher means more novel.\")\n",
        "        \n",
        "    def SampleTopNRecs(self, ml, testSubject=85, k=10):\n",
        "        \n",
        "        for algo in self.algorithms:\n",
        "            print(\"\\nUsing recommender \", algo.GetName())\n",
        "            \n",
        "            print(\"\\nBuilding recommendation model...\")\n",
        "            trainSet = self.dataset.GetFullTrainSet()\n",
        "            algo.GetAlgorithm().fit(trainSet)\n",
        "            \n",
        "            print(\"Computing recommendations...\")\n",
        "            testSet = self.dataset.GetAntiTestSetForUser(testSubject)\n",
        "        \n",
        "            predictions = algo.GetAlgorithm().test(testSet)\n",
        "            \n",
        "            recommendations = []\n",
        "            \n",
        "            print (\"\\nWe recommend:\")\n",
        "            for userID, movieID, actualRating, estimatedRating, _ in predictions:\n",
        "                intMovieID = int(movieID)\n",
        "                recommendations.append((intMovieID, estimatedRating))\n",
        "            \n",
        "            recommendations.sort(key=lambda x: x[1], reverse=True)\n",
        "            \n",
        "            for ratings in recommendations[:10]:\n",
        "                print(ml.getMovieName(ratings[0]), ratings[1])"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPbjkBzfQgmo"
      },
      "source": [
        "class ContentKNNAlgorithm(AlgoBase):\n",
        "\n",
        "    def __init__(self, k=40, sim_options={}):\n",
        "        AlgoBase.__init__(self)\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, trainset):\n",
        "        AlgoBase.fit(self, trainset)\n",
        "\n",
        "        # Compute item similarity matrix based on content attributes\n",
        "\n",
        "        # Load up genre vectors for every movie\n",
        "        ml = MovieLens()\n",
        "        genres = ml.getGenres()\n",
        "        years = ml.getYears()\n",
        "        mes = ml.getMiseEnScene()\n",
        "        \n",
        "        print(\"Computing content-based similarity matrix...\")\n",
        "            \n",
        "        # Compute genre distance for every movie combination as a 2x2 matrix\n",
        "        self.similarities = np.zeros((self.trainset.n_items, self.trainset.n_items))\n",
        "        \n",
        "        for thisRating in range(self.trainset.n_items):\n",
        "            if (thisRating % 100 == 0):\n",
        "                print(thisRating, \" of \", self.trainset.n_items)\n",
        "            for otherRating in range(thisRating+1, self.trainset.n_items):\n",
        "                thisMovieID = int(self.trainset.to_raw_iid(thisRating))\n",
        "                otherMovieID = int(self.trainset.to_raw_iid(otherRating))\n",
        "                genreSimilarity = self.computeGenreSimilarity(thisMovieID, otherMovieID, genres)\n",
        "                yearSimilarity = self.computeYearSimilarity(thisMovieID, otherMovieID, years)\n",
        "                #mesSimilarity = self.computeMiseEnSceneSimilarity(thisMovieID, otherMovieID, mes)\n",
        "                self.similarities[thisRating, otherRating] = genreSimilarity * yearSimilarity\n",
        "                self.similarities[otherRating, thisRating] = self.similarities[thisRating, otherRating]\n",
        "                \n",
        "        print(\"...done.\")\n",
        "                \n",
        "        return self\n",
        "    \n",
        "    def computeGenreSimilarity(self, movie1, movie2, genres):\n",
        "        genres1 = genres[movie1]\n",
        "        genres2 = genres[movie2]\n",
        "        sumxx, sumxy, sumyy = 0, 0, 0\n",
        "        for i in range(len(genres1)):\n",
        "            x = genres1[i]\n",
        "            y = genres2[i]\n",
        "            sumxx += x * x\n",
        "            sumyy += y * y\n",
        "            sumxy += x * y\n",
        "        \n",
        "        return sumxy/math.sqrt(sumxx*sumyy)\n",
        "    \n",
        "    def computeYearSimilarity(self, movie1, movie2, years):\n",
        "        diff = abs(years[movie1] - years[movie2])\n",
        "        sim = math.exp(-diff / 10.0)\n",
        "        return sim\n",
        "    \n",
        "    def computeMiseEnSceneSimilarity(self, movie1, movie2, mes):\n",
        "        mes1 = mes[movie1]\n",
        "        mes2 = mes[movie2]\n",
        "        if (mes1 and mes2):\n",
        "            shotLengthDiff = math.fabs(mes1[0] - mes2[0])\n",
        "            colorVarianceDiff = math.fabs(mes1[1] - mes2[1])\n",
        "            motionDiff = math.fabs(mes1[3] - mes2[3])\n",
        "            lightingDiff = math.fabs(mes1[5] - mes2[5])\n",
        "            numShotsDiff = math.fabs(mes1[6] - mes2[6])\n",
        "            return shotLengthDiff * colorVarianceDiff * motionDiff * lightingDiff * numShotsDiff\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def estimate(self, u, i):\n",
        "\n",
        "        if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
        "            raise PredictionImpossible('User and/or item is unkown.')\n",
        "        \n",
        "        # Build up similarity scores between this item and everything the user rated\n",
        "        neighbors = []\n",
        "        for rating in self.trainset.ur[u]:\n",
        "            genreSimilarity = self.similarities[i,rating[0]]\n",
        "            neighbors.append( (genreSimilarity, rating[1]) )\n",
        "        \n",
        "        # Extract the top-K most-similar ratings\n",
        "        k_neighbors = heapq.nlargest(self.k, neighbors, key=lambda t: t[0])\n",
        "        \n",
        "        # Compute average sim score of K neighbors weighted by user ratings\n",
        "        simTotal = weightedSum = 0\n",
        "        for (simScore, rating) in k_neighbors:\n",
        "            if (simScore > 0):\n",
        "                simTotal += simScore\n",
        "                weightedSum += simScore * rating\n",
        "            \n",
        "        if (simTotal == 0):\n",
        "            raise PredictionImpossible('No neighbors')\n",
        "\n",
        "        predictedRating = weightedSum / simTotal\n",
        "\n",
        "        return predictedRating"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRfrVcaZAoZ4",
        "outputId": "780b927f-85eb-4fe0-8c37-ee872186066c"
      },
      "source": [
        "import random\n",
        "from surprise import NormalPredictor\n",
        "\n",
        "def LoadMovieLensData():\n",
        "    ml = MovieLens()\n",
        "    print(\"Loading movie ratings...\")\n",
        "    data = ml.loadMovieLensLatestSmall()\n",
        "    print(\"\\nComputing movie popularity ranks so we can measure novelty later...\")\n",
        "    rankings = ml.getPopularityRanks()\n",
        "    return (ml, data, rankings)\n",
        "\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "\n",
        "# Load up common data set for the recommender algorithms\n",
        "(ml, evaluationData, rankings) = LoadMovieLensData()\n",
        "\n",
        "# Construct an Evaluator to, you know, evaluate them\n",
        "evaluator = Evaluator(evaluationData, rankings)\n",
        "\n",
        "contentKNN = ContentKNNAlgorithm()\n",
        "evaluator.AddAlgorithm(contentKNN, \"ContentKNN\")\n",
        "\n",
        "# Just make random recommendations\n",
        "Random = NormalPredictor()\n",
        "evaluator.AddAlgorithm(Random, \"Random\")\n",
        "\n",
        "evaluator.Evaluate(False)\n",
        "\n",
        "evaluator.SampleTopNRecs(ml)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading movie ratings...\n",
            "\n",
            "Computing movie popularity ranks so we can measure novelty later...\n",
            "Estimating biases using als...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Evaluating  ContentKNN ...\n",
            "Evaluating accuracy...\n",
            "Computing content-based similarity matrix...\n",
            "0  of  8211\n",
            "100  of  8211\n",
            "200  of  8211\n",
            "300  of  8211\n",
            "400  of  8211\n",
            "500  of  8211\n",
            "600  of  8211\n",
            "700  of  8211\n",
            "800  of  8211\n",
            "900  of  8211\n",
            "1000  of  8211\n",
            "1100  of  8211\n",
            "1200  of  8211\n",
            "1300  of  8211\n",
            "1400  of  8211\n",
            "1500  of  8211\n",
            "1600  of  8211\n",
            "1700  of  8211\n",
            "1800  of  8211\n",
            "1900  of  8211\n",
            "2000  of  8211\n",
            "2100  of  8211\n",
            "2200  of  8211\n",
            "2300  of  8211\n",
            "2400  of  8211\n",
            "2500  of  8211\n",
            "2600  of  8211\n",
            "2700  of  8211\n",
            "2800  of  8211\n",
            "2900  of  8211\n",
            "3000  of  8211\n",
            "3100  of  8211\n",
            "3200  of  8211\n",
            "3300  of  8211\n",
            "3400  of  8211\n",
            "3500  of  8211\n",
            "3600  of  8211\n",
            "3700  of  8211\n",
            "3800  of  8211\n",
            "3900  of  8211\n",
            "4000  of  8211\n",
            "4100  of  8211\n",
            "4200  of  8211\n",
            "4300  of  8211\n",
            "4400  of  8211\n",
            "4500  of  8211\n",
            "4600  of  8211\n",
            "4700  of  8211\n",
            "4800  of  8211\n",
            "4900  of  8211\n",
            "5000  of  8211\n",
            "5100  of  8211\n",
            "5200  of  8211\n",
            "5300  of  8211\n",
            "5400  of  8211\n",
            "5500  of  8211\n",
            "5600  of  8211\n",
            "5700  of  8211\n",
            "5800  of  8211\n",
            "5900  of  8211\n",
            "6000  of  8211\n",
            "6100  of  8211\n",
            "6200  of  8211\n",
            "6300  of  8211\n",
            "6400  of  8211\n",
            "6500  of  8211\n",
            "6600  of  8211\n",
            "6700  of  8211\n",
            "6800  of  8211\n",
            "6900  of  8211\n",
            "7000  of  8211\n",
            "7100  of  8211\n",
            "7200  of  8211\n",
            "7300  of  8211\n",
            "7400  of  8211\n",
            "7500  of  8211\n",
            "7600  of  8211\n",
            "7700  of  8211\n",
            "7800  of  8211\n",
            "7900  of  8211\n",
            "8000  of  8211\n",
            "8100  of  8211\n",
            "8200  of  8211\n",
            "...done.\n",
            "Analysis complete.\n",
            "Evaluating  Random ...\n",
            "Evaluating accuracy...\n",
            "Analysis complete.\n",
            "\n",
            "\n",
            "Algorithm  RMSE       MAE       \n",
            "ContentKNN 0.9375     0.7263    \n",
            "Random     1.4385     1.1478    \n",
            "\n",
            "Legend:\n",
            "\n",
            "RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\n",
            "MAE:       Mean Absolute Error. Lower values mean better accuracy.\n",
            "\n",
            "Using recommender  ContentKNN\n",
            "\n",
            "Building recommendation model...\n",
            "Computing content-based similarity matrix...\n",
            "0  of  9066\n",
            "100  of  9066\n",
            "200  of  9066\n",
            "300  of  9066\n",
            "400  of  9066\n",
            "500  of  9066\n",
            "600  of  9066\n",
            "700  of  9066\n",
            "800  of  9066\n",
            "900  of  9066\n",
            "1000  of  9066\n",
            "1100  of  9066\n",
            "1200  of  9066\n",
            "1300  of  9066\n",
            "1400  of  9066\n",
            "1500  of  9066\n",
            "1600  of  9066\n",
            "1700  of  9066\n",
            "1800  of  9066\n",
            "1900  of  9066\n",
            "2000  of  9066\n",
            "2100  of  9066\n",
            "2200  of  9066\n",
            "2300  of  9066\n",
            "2400  of  9066\n",
            "2500  of  9066\n",
            "2600  of  9066\n",
            "2700  of  9066\n",
            "2800  of  9066\n",
            "2900  of  9066\n",
            "3000  of  9066\n",
            "3100  of  9066\n",
            "3200  of  9066\n",
            "3300  of  9066\n",
            "3400  of  9066\n",
            "3500  of  9066\n",
            "3600  of  9066\n",
            "3700  of  9066\n",
            "3800  of  9066\n",
            "3900  of  9066\n",
            "4000  of  9066\n",
            "4100  of  9066\n",
            "4200  of  9066\n",
            "4300  of  9066\n",
            "4400  of  9066\n",
            "4500  of  9066\n",
            "4600  of  9066\n",
            "4700  of  9066\n",
            "4800  of  9066\n",
            "4900  of  9066\n",
            "5000  of  9066\n",
            "5100  of  9066\n",
            "5200  of  9066\n",
            "5300  of  9066\n",
            "5400  of  9066\n",
            "5500  of  9066\n",
            "5600  of  9066\n",
            "5700  of  9066\n",
            "5800  of  9066\n",
            "5900  of  9066\n",
            "6000  of  9066\n",
            "6100  of  9066\n",
            "6200  of  9066\n",
            "6300  of  9066\n",
            "6400  of  9066\n",
            "6500  of  9066\n",
            "6600  of  9066\n",
            "6700  of  9066\n",
            "6800  of  9066\n",
            "6900  of  9066\n",
            "7000  of  9066\n",
            "7100  of  9066\n",
            "7200  of  9066\n",
            "7300  of  9066\n",
            "7400  of  9066\n",
            "7500  of  9066\n",
            "7600  of  9066\n",
            "7700  of  9066\n",
            "7800  of  9066\n",
            "7900  of  9066\n",
            "8000  of  9066\n",
            "8100  of  9066\n",
            "8200  of  9066\n",
            "8300  of  9066\n",
            "8400  of  9066\n",
            "8500  of  9066\n",
            "8600  of  9066\n",
            "8700  of  9066\n",
            "8800  of  9066\n",
            "8900  of  9066\n",
            "9000  of  9066\n",
            "...done.\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Presidio, The (1988) 3.841314676872932\n",
            "Femme Nikita, La (Nikita) (1990) 3.839613347087336\n",
            "Wyatt Earp (1994) 3.8125061475551796\n",
            "Shooter, The (1997) 3.8125061475551796\n",
            "Bad Girls (1994) 3.8125061475551796\n",
            "The Hateful Eight (2015) 3.812506147555179\n",
            "True Grit (2010) 3.812506147555179\n",
            "Open Range (2003) 3.812506147555179\n",
            "Big Easy, The (1987) 3.7835412549266985\n",
            "Point Break (1991) 3.764158410102279\n",
            "\n",
            "Using recommender  Random\n",
            "\n",
            "Building recommendation model...\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Sleepers (1996) 5\n",
            "Beavis and Butt-Head Do America (1996) 5\n",
            "Fear and Loathing in Las Vegas (1998) 5\n",
            "Happiness (1998) 5\n",
            "Summer of Sam (1999) 5\n",
            "Bowling for Columbine (2002) 5\n",
            "Babe (1995) 5\n",
            "Birdcage, The (1996) 5\n",
            "Carlito's Way (1993) 5\n",
            "Wizard of Oz, The (1939) 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwm2jwhKe2Az"
      },
      "source": [
        ""
      ],
      "execution_count": 70,
      "outputs": []
    }
  ]
}